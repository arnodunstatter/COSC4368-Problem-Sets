{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import IPython\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUDENT ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STUDENT1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STUDENT2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUDENT3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDENT4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUDENT5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>STUDENT141</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>STUDENT142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>STUDENT143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>STUDENT144</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>STUDENT145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STUDENT ID  1  2  3  4  5  6  7  8  9  ...  23  24  25  26  27  28  29  \\\n",
       "0      STUDENT1  2  2  3  3  1  2  2  1  1  ...   1   1   3   2   1   2   1   \n",
       "1      STUDENT2  2  2  3  3  1  2  2  1  1  ...   1   1   3   2   3   2   2   \n",
       "2      STUDENT3  2  2  2  3  2  2  2  2  4  ...   1   1   2   2   1   1   2   \n",
       "3      STUDENT4  1  1  1  3  1  2  1  2  1  ...   1   2   3   2   2   1   3   \n",
       "4      STUDENT5  2  2  1  3  2  2  1  3  1  ...   2   1   2   2   2   1   2   \n",
       "..          ... .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "140  STUDENT141  2  1  2  3  1  1  2  1  1  ...   1   1   2   1   2   1   3   \n",
       "141  STUDENT142  1  1  2  4  2  2  2  1  4  ...   1   1   3   2   2   1   5   \n",
       "142  STUDENT143  1  1  1  4  2  2  2  1  1  ...   1   1   3   3   2   1   4   \n",
       "143  STUDENT144  2  1  2  4  1  1  1  5  2  ...   2   1   2   1   2   1   5   \n",
       "144  STUDENT145  1  1  1  5  2  2  2  3  1  ...   2   1   3   2   3   1   5   \n",
       "\n",
       "     30  31  GRADE  \n",
       "0     1   1      1  \n",
       "1     3   1      1  \n",
       "2     2   1      1  \n",
       "3     2   1      1  \n",
       "4     2   1      1  \n",
       "..   ..  ..    ...  \n",
       "140   3   9      5  \n",
       "141   3   9      5  \n",
       "142   3   9      1  \n",
       "143   3   9      4  \n",
       "144   4   9      3  \n",
       "\n",
       "[145 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DATA.csv\",delimiter=\";\")\n",
    "'''\n",
    "Student ID\n",
    "1- Student Age (1: 18-21, 2: 22-25, 3: above 26)\n",
    "2- Sex (1: female, 2: male)\n",
    "3- Graduated high-school type: (1: private, 2: state, 3: other)\n",
    "4- Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)\n",
    "5- Additional work: (1: Yes, 2: No)\n",
    "6- Regular artistic or sports activity: (1: Yes, 2: No)\n",
    "7- Do you have a partner: (1: Yes, 2: No)\n",
    "8- Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)\n",
    "9- Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)\n",
    "10- Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)\n",
    "11- Mother's education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)\n",
    "12- Father's education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)\n",
    "13- Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)\n",
    "14- Parental status: (1: married, 2: divorced, 3: died - one of them or both)\n",
    "15- Mother's occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)\n",
    "16- Father's occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)\n",
    "17- Weekly study hours: (1: None, 2: <5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)\n",
    "18- Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)\n",
    "19- Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)\n",
    "20- Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)\n",
    "21- Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)\n",
    "22- Attendance to classes (1: always, 2: sometimes, 3: never)\n",
    "23- Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)\n",
    "24- Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)\n",
    "25- Taking notes in classes: (1: never, 2: sometimes, 3: always)\n",
    "26- Listening in classes: (1: never, 2: sometimes, 3: always)\n",
    "27- Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)\n",
    "28- Flip-classroom: (1: not useful, 2: useful, 3: not applicable)\n",
    "29- Cumulative grade point average in the last semester (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)\n",
    "30- Expected Cumulative grade point average in the graduation (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)\n",
    "31- Course ID\n",
    "32- OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)\n",
    "'''\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Testing Split\n",
    "Split such that the training set has 100 observations and the testing set has 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[df.columns[1:32]])\n",
    "y = np.array(df[\"GRADE\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.31, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch for SVM-HyperParameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block iterates through all combinations of kernels, C values, gamma values, class weight values, and, if applicable, degree values\n",
    "# then it evaluates the SVM produced with those hyperparameters, both by accuracy and by MAE\n",
    "def make_SVM_return_eval_and_params(k, c, g, cw, d, folds=10):\n",
    "    SVM = svm.SVC(random_state=0, kernel=k, C=c, gamma=g, class_weight=cw, degree=d)\n",
    "    accuracyScores = cross_val_score(SVM, X_train, y_train, cv=KFold(folds))\n",
    "    avgAccuracyScore = np.mean(accuracyScores)\n",
    "    maeScores = cross_val_score(SVM, X_train, y_train, cv=KFold(folds), scoring='neg_mean_absolute_error')\n",
    "    avgMaeScore = np.mean(maeScores)\n",
    "    return [avgAccuracyScore, avgMaeScore, k, c, g, cw, d]\n",
    "    \n",
    "all_SVM_Models = [] #each inner list will start with the average of all 10-fold scores and then contain each hyperparameter associated with the SVM that produced that score\n",
    "for k in ['linear','poly','rbf','sigmoid']: # kernel\n",
    "    for c in range(1,10): # C\n",
    "        for g in ['scale','auto']: # gamma\n",
    "            for cw in ['balanced',None]: # class weight\n",
    "                if k == 'poly':\n",
    "                    for d in range(1,11):\n",
    "                        all_SVM_Models.append(make_SVM_return_eval_and_params(k, c, g, cw, d))\n",
    "                else:\n",
    "                    d=3 #degree=3 by default\n",
    "                    all_SVM_Models.append(make_SVM_return_eval_and_params(k, c, g, cw, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using highest accuracy as performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using 10-fold cross validation, the top 10 models (evaluated by highest accuracy) were made with...\n",
      "[1] kernel='poly', C=1, gamma='auto', class_weight=None, degree=1. This gave an average training accuracy of\t\t\t0.25\n",
      "[2] kernel='poly', C=5, gamma='auto', class_weight=None, degree=1. This gave an average training accuracy of\t\t\t0.25\n",
      "[3] kernel='poly', C=8, gamma='scale', class_weight=None, degree=1. This gave an average training accuracy of\t\t\t0.25\n",
      "[4] kernel='poly', C=1, gamma='scale', class_weight=None, degree=2. This gave an average training accuracy of\t\t\t0.24000000000000005\n",
      "[5] kernel='poly', C=7, gamma='scale', class_weight=None, degree=1. This gave an average training accuracy of\t\t\t0.24\n",
      "[6] kernel='linear', C=1, gamma='scale', class_weight='balanced', degree=3. This gave an average training accuracy of\t\t\t0.23000000000000004\n",
      "[7] kernel='linear', C=1, gamma='auto', class_weight='balanced', degree=3. This gave an average training accuracy of\t\t\t0.23000000000000004\n",
      "[8] kernel='poly', C=1, gamma='scale', class_weight='balanced', degree=7. This gave an average training accuracy of\t\t\t0.23000000000000004\n",
      "[9] kernel='poly', C=1, gamma='scale', class_weight='balanced', degree=9. This gave an average training accuracy of\t\t\t0.23000000000000004\n",
      "[10] kernel='poly', C=1, gamma='scale', class_weight='balanced', degree=10. This gave an average training accuracy of\t\t\t0.23000000000000004\n"
     ]
    }
   ],
   "source": [
    "SVM_bestAccuracyFirst = sorted(all_SVM_Models, key=lambda x:x[0], reverse=True) #reverse=True (highest first)\n",
    "print(\"When using 10-fold cross validation, the top 10 models (evaluated by highest accuracy) were made with...\")\n",
    "for i,hyperparameters in enumerate(SVM_bestAccuracyFirst[:10]):\n",
    "    avgAccuracyScore,avgMaeScore,k,c,g,cw,d = hyperparameters\n",
    "    cwSTR = None if cw == None else f\"'{cw}'\"\n",
    "    print(f\"[{i+1}] kernel='{k}', C={c}, gamma='{g}', class_weight={cwSTR}, degree={d}. This gave an average training accuracy of\\t\\t\\t{avgAccuracyScore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using lowest MAE (highest negative MAE) as performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using 10-fold cross validation, the top 10 models (evaluated by highest negative MAE) were made with...\n",
      "[1] kernel='rbf', C=4, gamma='scale', class_weight=None, degree=3. This gave an average training MAE of\t\t\t-1.5400000000000003\n",
      "[2] kernel='rbf', C=5, gamma='scale', class_weight='balanced', degree=3. This gave an average training MAE of\t\t\t-1.55\n",
      "[3] kernel='rbf', C=4, gamma='scale', class_weight='balanced', degree=3. This gave an average training MAE of\t\t\t-1.5699999999999998\n",
      "[4] kernel='rbf', C=3, gamma='scale', class_weight=None, degree=3. This gave an average training MAE of\t\t\t-1.57\n",
      "[5] kernel='linear', C=1, gamma='scale', class_weight='balanced', degree=3. This gave an average training MAE of\t\t\t-1.5799999999999998\n",
      "[6] kernel='linear', C=1, gamma='auto', class_weight='balanced', degree=3. This gave an average training MAE of\t\t\t-1.5799999999999998\n",
      "[7] kernel='rbf', C=3, gamma='scale', class_weight='balanced', degree=3. This gave an average training MAE of\t\t\t-1.5899999999999999\n",
      "[8] kernel='linear', C=1, gamma='scale', class_weight=None, degree=3. This gave an average training MAE of\t\t\t-1.5999999999999999\n",
      "[9] kernel='linear', C=1, gamma='auto', class_weight=None, degree=3. This gave an average training MAE of\t\t\t-1.5999999999999999\n",
      "[10] kernel='linear', C=2, gamma='scale', class_weight='balanced', degree=3. This gave an average training MAE of\t\t\t-1.5999999999999999\n"
     ]
    }
   ],
   "source": [
    "SVM_bestMaeFirst = sorted(all_SVM_Models, key=lambda x:x[1], reverse=True) #reverse=True (highest first)\n",
    "print(\"When using 10-fold cross validation, the top 10 models (evaluated by highest negative MAE) were made with...\")\n",
    "for i,hyperparameters in enumerate(SVM_bestMaeFirst[:10]):\n",
    "    avgAccuracyScore,avgMaeScore,k,c,g,cw,d = hyperparameters\n",
    "    cwSTR = None if cw == None else f\"'{cw}'\"\n",
    "    print(f\"[{i+1}] kernel='{k}', C={c}, gamma='{g}', class_weight={cwSTR}, degree={d}. This gave an average training MAE of\\t\\t\\t{avgMaeScore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the best 2 models\n",
    "We will select the best model from each performance metric. The model with the best Accuracy will be called \"bA\" and the model with the best MAE will be called \"bM\". Then each will have its accuracy and its Mean Absolute Error computed using 10 fold cross validation - further this will be done 1000 times with random shuffling of the data and the metrics averaged to obtain metrics unbiased by sampling chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "bM_SVM = svm.SVC(kernel=SVM_bestMaeFirst[0][2], C=SVM_bestMaeFirst[0][3], gamma=SVM_bestMaeFirst[0][4], class_weight=SVM_bestMaeFirst[0][5], degree=SVM_bestMaeFirst[0][6]).fit(X_train, y_train)\n",
    "SVM_bM_Accuracy = np.mean(np.array([np.mean(cross_val_score(bM_SVM, X_test, y_test, cv=KFold(k,shuffle=True))) for i in range(1000)]))\n",
    "SVM_bM_Mae = np.mean(np.array([np.mean(cross_val_score(bM_SVM, X_test, y_test, cv=KFold(k,shuffle=True), scoring='neg_mean_absolute_error')) for i in range(1000)]))\n",
    "\n",
    "bA_SVM = svm.SVC(kernel=SVM_bestAccuracyFirst[0][2], C=SVM_bestAccuracyFirst[0][3], gamma=SVM_bestAccuracyFirst[0][4], class_weight=SVM_bestAccuracyFirst[0][5], degree=SVM_bestAccuracyFirst[0][6]).fit(X_train, y_train)\n",
    "SVM_bA_Accuracy = np.mean(np.array([np.mean(cross_val_score(bA_SVM, X_test, y_test, cv=KFold(k,shuffle=True))) for i in range(1000)]))\n",
    "SVM_bA_Mae = np.mean(np.array([np.mean(cross_val_score(bA_SVM, X_test, y_test, cv=KFold(k,shuffle=True), scoring='neg_mean_absolute_error')) for i in range(1000)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>degree</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>testing_accuracy</th>\n",
       "      <th>validation_MAE</th>\n",
       "      <th>testing_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bM</th>\n",
       "      <td>rbf</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.242185</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>-1.990670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bA</th>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.273330</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-2.167535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  C  gamma class_weight  degree  validation_accuracy  \\\n",
       "bM    rbf  4  scale         None       3                 0.23   \n",
       "bA   poly  1   auto         None       1                 0.25   \n",
       "\n",
       "    testing_accuracy  validation_MAE  testing_MAE  \n",
       "bM          0.242185           -1.54    -1.990670  \n",
       "bA          0.273330           -1.95    -2.167535  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 0.31 = test proportion\n",
    "SVM_results =\\\n",
    "[\n",
    "    [SVM_bestMaeFirst[0][2], SVM_bestMaeFirst[0][3], SVM_bestMaeFirst[0][4], SVM_bestMaeFirst[0][5], SVM_bestMaeFirst[0][6], SVM_bestMaeFirst[0][0], SVM_bM_Accuracy, SVM_bestMaeFirst[0][1], SVM_bM_Mae],\n",
    "    [SVM_bestAccuracyFirst[0][2], SVM_bestAccuracyFirst[0][3], SVM_bestAccuracyFirst[0][4], SVM_bestAccuracyFirst[0][5], SVM_bestAccuracyFirst[0][6], SVM_bestAccuracyFirst[0][0], SVM_bA_Accuracy, SVM_bestAccuracyFirst[0][1], SVM_bA_Mae]\n",
    "]\n",
    "SVM_results = pd.DataFrame(SVM_results, index=['bM','bA'], columns=['kernel','C','gamma','class_weight','degree', 'validation_accuracy', 'testing_accuracy','validation_MAE', 'testing_MAE'])\n",
    "SVM_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching through our hyperparameters for good MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MLP_return_eval_and_params(hls, af, s, lrt, rate, folds=10):\n",
    "    MLP = neural_network.MLPClassifier(hidden_layer_sizes=hls, activation=af, solver=s, learning_rate=lrt, learning_rate_init=rate)\n",
    "    accuracyScores = cross_val_score(MLP, X_train, y_train, cv=KFold(folds))\n",
    "    avgAccuracyScore = np.mean(accuracyScores)\n",
    "    maeScores = cross_val_score(MLP, X_train, y_train, cv=KFold(folds), scoring='neg_mean_absolute_error')\n",
    "    avgMaeScore = np.mean(maeScores)\n",
    "    return [avgAccuracyScore, avgMaeScore, hls, af, s, lrt, rate]\n",
    "    \n",
    "all_MLP_Models = []\n",
    "for hls in [(50,), (100,), (200,)]: #hidden layer sizes\n",
    "    for af in ['identity','logistic','tanh','relu']: #activation function\n",
    "        for s in ['lbfgs','sgd','adam']: #solver\n",
    "            learning_rates = [0.01, 0.001, 0.0001]\n",
    "            if s == 'sgd':\n",
    "                for lrt in ['constant','invscaling','adaptive']: #learning rate type (called 'learning_rate' in sklearn params)\n",
    "                    for rate in learning_rates: #called 'learning_rate_init' in sklearn params\n",
    "                        all_MLP_Models.append(make_MLP_return_eval_and_params(hls, af, s, lrt, rate))\n",
    "            else:\n",
    "                lrt='constant' #default. LRT is only used by solver=='sgd'\n",
    "                if s == 'adam':\n",
    "                    for rate in learning_rates: #called 'learning_rate_init' in sklearn params\n",
    "                        all_MLP_Models.append(make_MLP_return_eval_and_params(hls, af, s, lrt, rate))\n",
    "                else:\n",
    "                    rate=0.001 #default. learning_rate_init is only used by solver=='adam' or solver=='sgd'\n",
    "                    all_MLP_Models.append(make_MLP_return_eval_and_params(hls, af, s, lrt, rate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using highest accuracy as performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using 10-fold cross validation, the top 10 models (evaluated by highest accuracy) were made with...\n",
      "[1] hidden_layer_sizes=(100,), activation='logistic', solver='lbfgs' learning_rate='constant', learning_rate_init=0.001. This gave an average training accuracy of\t\t\t0.23000000000000004\n",
      "[2] hidden_layer_sizes=(100,), activation='relu', solver='sgd' learning_rate='adaptive', learning_rate_init=0.001. This gave an average training accuracy of\t\t\t0.23000000000000004\n",
      "[3] hidden_layer_sizes=(50,), activation='tanh', solver='adam' learning_rate='constant', learning_rate_init=0.01. This gave an average training accuracy of\t\t\t0.22000000000000003\n",
      "[4] hidden_layer_sizes=(100,), activation='tanh', solver='sgd' learning_rate='adaptive', learning_rate_init=0.001. This gave an average training accuracy of\t\t\t0.21999999999999997\n",
      "[5] hidden_layer_sizes=(50,), activation='identity', solver='sgd' learning_rate='adaptive', learning_rate_init=0.001. This gave an average training accuracy of\t\t\t0.21000000000000002\n",
      "[6] hidden_layer_sizes=(50,), activation='relu', solver='sgd' learning_rate='constant', learning_rate_init=0.01. This gave an average training accuracy of\t\t\t0.21000000000000002\n",
      "[7] hidden_layer_sizes=(100,), activation='identity', solver='adam' learning_rate='constant', learning_rate_init=0.0001. This gave an average training accuracy of\t\t\t0.21000000000000002\n",
      "[8] hidden_layer_sizes=(100,), activation='relu', solver='sgd' learning_rate='constant', learning_rate_init=0.001. This gave an average training accuracy of\t\t\t0.21000000000000002\n",
      "[9] hidden_layer_sizes=(200,), activation='logistic', solver='sgd' learning_rate='invscaling', learning_rate_init=0.01. This gave an average training accuracy of\t\t\t0.21000000000000002\n",
      "[10] hidden_layer_sizes=(200,), activation='tanh', solver='sgd' learning_rate='constant', learning_rate_init=0.0001. This gave an average training accuracy of\t\t\t0.21000000000000002\n"
     ]
    }
   ],
   "source": [
    "MLP_bestAccuracyFirst = sorted(all_MLP_Models, key=lambda x:x[0], reverse=True) #reverse=True (highest first)\n",
    "print(\"When using 10-fold cross validation, the top 10 models (evaluated by highest accuracy) were made with...\")\n",
    "for i,hyperparameters in enumerate(MLP_bestAccuracyFirst[:10]):\n",
    "    avgAccuracyScore, avgMaeScore, hls, af, s, lrt, rate = hyperparameters\n",
    "    print(f\"[{i+1}] hidden_layer_sizes={hls}, activation='{af}', solver='{s}' learning_rate='{lrt}', learning_rate_init={rate}. This gave an average training accuracy of\\t\\t\\t{avgAccuracyScore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using lowest MAE (highest negative MAE) as performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using 10-fold cross validation, the top 10 models (evaluated by highest negative MAE) were made with...\n",
      "[1] hidden_layer_sizes=(50,), activation='tanh', solver='lbfgs' learning_rate='constant', learning_rate_init=0.001. This gave an average training MAE of\t\t\t-1.58\n",
      "[2] hidden_layer_sizes=(200,), activation='relu', solver='sgd' learning_rate='adaptive', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.6\n",
      "[3] hidden_layer_sizes=(100,), activation='relu', solver='sgd' learning_rate='constant', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.65\n",
      "[4] hidden_layer_sizes=(50,), activation='tanh', solver='sgd' learning_rate='adaptive', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.6799999999999997\n",
      "[5] hidden_layer_sizes=(200,), activation='tanh', solver='sgd' learning_rate='adaptive', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.69\n",
      "[6] hidden_layer_sizes=(200,), activation='logistic', solver='lbfgs' learning_rate='constant', learning_rate_init=0.001. This gave an average training MAE of\t\t\t-1.7\n",
      "[7] hidden_layer_sizes=(100,), activation='tanh', solver='lbfgs' learning_rate='constant', learning_rate_init=0.001. This gave an average training MAE of\t\t\t-1.72\n",
      "[8] hidden_layer_sizes=(100,), activation='tanh', solver='adam' learning_rate='constant', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.72\n",
      "[9] hidden_layer_sizes=(100,), activation='relu', solver='sgd' learning_rate='adaptive', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.72\n",
      "[10] hidden_layer_sizes=(100,), activation='tanh', solver='sgd' learning_rate='constant', learning_rate_init=0.01. This gave an average training MAE of\t\t\t-1.73\n"
     ]
    }
   ],
   "source": [
    "MLP_bestMaeFirst = sorted(all_MLP_Models, key=lambda x:x[1], reverse=True) #reverse=True (highest first)\n",
    "print(\"When using 10-fold cross validation, the top 10 models (evaluated by highest negative MAE) were made with...\")\n",
    "for i,hyperparameters in enumerate(MLP_bestMaeFirst[:10]):\n",
    "    avgAccuracyScore, avgMaeScore, hls, af, s, lrt, rate = hyperparameters\n",
    "    print(f\"[{i+1}] hidden_layer_sizes={hls}, activation='{af}', solver='{s}' learning_rate='{lrt}', learning_rate_init={rate}. This gave an average training MAE of\\t\\t\\t{avgMaeScore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the best 2 MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "\n",
    "bM_MLP = neural_network.MLPClassifier(hidden_layer_sizes=MLP_bestMaeFirst[0][2], activation=MLP_bestMaeFirst[0][3], solver=MLP_bestMaeFirst[0][4], learning_rate=MLP_bestMaeFirst[0][5], learning_rate_init=MLP_bestMaeFirst[0][6]).fit(X_train, y_train)\n",
    "MLP_bM_Accuracy = np.mean(np.array([np.mean(cross_val_score(bM_MLP, X_test, y_test, cv=KFold(k,shuffle=True), error_score='raise')) for i in range(1000)]))\n",
    "MLP_bM_Mae = np.mean(np.array([np.mean(cross_val_score(bM_MLP, X_test, y_test, cv=KFold(k,shuffle=True), scoring='neg_mean_absolute_error')) for i in range(1000)]))\n",
    "\n",
    "bA_MLP = neural_network.MLPClassifier(hidden_layer_sizes=MLP_bestAccuracyFirst[0][2], activation=MLP_bestAccuracyFirst[0][3], solver=MLP_bestAccuracyFirst[0][4], learning_rate=MLP_bestAccuracyFirst[0][5], learning_rate_init=MLP_bestAccuracyFirst[0][6]).fit(X_train, y_train)\n",
    "MLP_bA_Accuracy = np.mean(np.array([np.mean(cross_val_score(bA_MLP, X_test, y_test, cv=KFold(k,shuffle=True))) for i in range(1000)]))\n",
    "MLP_bA_Mae = np.mean(np.array([np.mean(cross_val_score(bA_MLP, X_test, y_test, cv=KFold(k,shuffle=True), scoring='neg_mean_absolute_error')) for i in range(1000)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>testing_accuracy</th>\n",
       "      <th>validation_MAE</th>\n",
       "      <th>testing_MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bM</th>\n",
       "      <td>(50,)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.226990</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.97330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bA</th>\n",
       "      <td>(100,)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.256895</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.77231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_layer_sizes activation solver learning_rate  learning_rate_init  \\\n",
       "bM              (50,)       tanh  lbfgs      constant               0.001   \n",
       "bA             (100,)   logistic  lbfgs      constant               0.001   \n",
       "\n",
       "    validation_accuracy  testing_accuracy  validation_MAE  testing_MAE  \n",
       "bM                 0.14          0.226990           -1.58     -1.97330  \n",
       "bA                 0.23          0.256895           -1.76     -1.77231  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 0.31 = test proportion\n",
    "MLP_results =\\\n",
    "[\n",
    "    [MLP_bestMaeFirst[0][2], MLP_bestMaeFirst[0][3], MLP_bestMaeFirst[0][4], MLP_bestMaeFirst[0][5], MLP_bestMaeFirst[0][6], MLP_bestMaeFirst[0][0], MLP_bM_Accuracy, MLP_bestMaeFirst[0][1], MLP_bM_Mae],\n",
    "    [MLP_bestAccuracyFirst[0][2], MLP_bestAccuracyFirst[0][3], MLP_bestAccuracyFirst[0][4], MLP_bestAccuracyFirst[0][5], MLP_bestAccuracyFirst[0][6], MLP_bestAccuracyFirst[0][0], MLP_bA_Accuracy, MLP_bestAccuracyFirst[0][1], MLP_bA_Mae]\n",
    "]\n",
    "MLP_results = pd.DataFrame(MLP_results, index=['bM','bA'], columns=['hidden_layer_sizes', 'activation', 'solver', 'learning_rate', 'learning_rate_init', 'validation_accuracy', 'testing_accuracy','validation_MAE', 'testing_MAE'])\n",
    "MLP_results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
